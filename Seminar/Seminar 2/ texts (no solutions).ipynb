{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в автоматическую обработку текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Регулярные выражения__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Классы символов:*__\n",
    "\n",
    "__[A-Z]__ - символы верхнего регистра (латиница)\n",
    "\n",
    "__[a-z]__ - символы нижнего регистра (латиница)\n",
    "\n",
    "__[А-Я]__ - символы верхнего регистра (кириллица)\n",
    "\n",
    "__[а-я]__ - символы нижнего регистра (кириллица)\n",
    "\n",
    "__[0-9]__ или \\d - цифра\n",
    "\n",
    "__[^0-9]__ или \\D - любой символ, кроме цифры\n",
    "\n",
    "__.__ - любой символ\n",
    "\n",
    "__*Служебные символы:*__\n",
    "\n",
    "__\\t__ - табуляция\n",
    "\n",
    "__\\s__ - любой пробельный символ\n",
    "\n",
    "__\\S__ - все символы, кроме пробельных\n",
    "\n",
    "__\\n__  - перенос строки\n",
    "\n",
    "__^__ - начало строки\n",
    "\n",
    "__$__ - конец строки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Операторы:*__\n",
    "\n",
    "__?__ - предыдущий символ/группа может быть, а может не быть\n",
    "\n",
    "__+__ - предыдущий символ/группа может повторяться 1 и более раз\n",
    "\n",
    "__*__ - предыдущий символ/группа может повторяться 0 и более раз\n",
    "\n",
    "__{n,m}__ - предыдущий символ/группа может повторяться от от n до m включительно\n",
    "\n",
    "__{n,}__ - предыдущий символ/группа в скобках может повторяться n и более раз\n",
    "\n",
    "__{,m}__ - предыдущий символ/группа может повторяться до m раз\n",
    "\n",
    "__{n}__ - предыдущий символ/группа повторяется n раз\n",
    "\n",
    "Внутри групп не работают операторы __.__, __+__, __*__, их необходимо экранировать с помощью обратного слеша: \\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Методы:*__\n",
    "\n",
    "__re.match(pattern, string)__ - найти подстроку pattern в начале строки string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(0, 5), match='рыбак'>\n",
      "рыбак\n",
      "0 5\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "m = re.match(r'рыбак', 'рыбак рыбака видит издалека')\n",
    "\n",
    "print(m)\n",
    "print(m.group(0))\n",
    "print(m.start(), m.end())\n",
    "\n",
    "l = re.match(r'видит', 'рыбак рыбака видит издалека')\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__re.search(pattern, string)__ - аналогичен методу match, но ищет не только в начале строки (но возвращает только первое вхождение!)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(19, 27), match='издалека'>\n",
      "издалека\n",
      "19 27\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "m = re.search(r'издалека', 'рыбак рыбака видит издалека')\n",
    "\n",
    "print(m)\n",
    "print(m.group(0))\n",
    "print(m.start(), m.end())\n",
    "\n",
    "l = re.search(r'прорубь', 'рыбак рыбака видит издалека')\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__re.findall(pattern, string)__ -  возвращает все вхождения pattern в string в виде списка\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['рыбак', 'рыбак']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "m = re.findall(r'рыбак', 'рыбак рыбака видит издалека')\n",
    "\n",
    "print(m)\n",
    "\n",
    "l = re.findall(r'прорубь', 'рыбак рыбака видит издалека')\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__re.split(pattern, string, [maxsplit=0])__ - разделяет строку string по шаблону pattern; параметр maxsplit отвечает за максимальное количество разбиений (если их существует несколько).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['рыбак рыбака ', ' издалека']\n",
      "['', ' ', 'а видит издалека'] 3\n",
      "['', ' рыбака видит издалека'] 2\n"
     ]
    }
   ],
   "source": [
    "m = re.split(r'видит', 'рыбак рыбака видит издалека')\n",
    "\n",
    "print(m)\n",
    "\n",
    "l = re.split(r'рыбак', 'рыбак рыбака видит издалека')\n",
    "print(l, len(l))\n",
    "\n",
    "l1 = re.split(r'рыбак', 'рыбак рыбака видит издалека',maxsplit=1)\n",
    "print(l1, len(l1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__re.sub(pattern, string2, string1)__ - заменяет все вхождения pattern в string1 на srting2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Рыбак Рыбака видит издалека\n"
     ]
    }
   ],
   "source": [
    "m = re.sub(r'рыбак', 'Рыбак', 'рыбак рыбака видит издалека')\n",
    "\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__re.compile(pattern)__ - создает объект для последующего поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['рыбак', 'рыбак']\n"
     ]
    }
   ],
   "source": [
    "prog = re.compile(r'рыбак')\n",
    "\n",
    "m = prog.findall('рыбак рыбака видит издалека')\n",
    "\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Р', 'В']\n"
     ]
    }
   ],
   "source": [
    "prog = re.compile('[A-Я]') # поиск всех заглавныех букв в строке\n",
    "\n",
    "m = prog.findall('Рыбак рыбака видит издалека. Всегда!')\n",
    "\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Примеры:*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "у456ао, ы234ег, 99авто443\n",
      "у456ао\n"
     ]
    }
   ],
   "source": [
    "prog = re.compile('[авекорсту]{1}[0-9]{3}[авекорсту]{2}') # регулярное выражение для поиска автомобильных\n",
    "                                                          # номеров (русские буквы, совпадающие с латиницей)\n",
    "\n",
    "s = 'у456ао, ы234ег, 99авто443'\n",
    "print(s)\n",
    "res = prog.findall(s)\n",
    "\n",
    "print(*res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['кот котик компот']\n",
      "['кот', 'кот', 'к компот']\n",
      "['кот', 'кот', 'компот']\n",
      "['кот котик ']\n"
     ]
    }
   ],
   "source": [
    "# пример \"жадных\" операторов: ищем котов\n",
    "\n",
    "s = 'кот котик компот'\n",
    "res1 = re.findall(r'к.*т', s)\n",
    "print(res1)\n",
    "\n",
    "res2 = re.findall(r'к.*?т', s)\n",
    "print(res2)\n",
    "\n",
    "res3 = re.findall(r'к[\\S]*?т', s)\n",
    "print(res3)\n",
    "\n",
    "res4 = re.findall(r'кот.*\\s', s)\n",
    "print(res4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задание 1:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите в тексте все номера телефонов; текст лежит в файле 'task1.txt'. Обратите внимание на возможные форматы написания номеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гарантируется, что в номере 8 цифр и он отделен пробелом, но форматы написания могут отличаться:\n",
      "\n",
      "\n",
      "89268659970\tАнна\n",
      "8(495)3451212\tАлексей Иванин\n",
      "Автомастерская\t+7(234)456-78-90\n",
      "8(956)234-23-23\tсоседка 125 квартира\n",
      "Офис, 5 этаж\t85679962312 \n",
      "Игорь\t\t+7-845-344-23-65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "with open ('task1.txt') as f:\n",
    "    phones = f.read()\n",
    "    \n",
    "print(phones)\n",
    "\n",
    "#здесь Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Токенизация с помощью регулярных выражений__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "«Карты, деньги, два ствола» культовый фильм Гая Ричи. Эта картина покорила сначала Британию, затем Америку, а потом и весь мир. Никому неизвестный режиссер Гай Ричи, у которого за плечами были только коротметражка «Трудное дело», дешевые рекламные ролики и клипы, создал шедевр на все времена. Это именно тот случай, когда и критики, и зрители в восторге. Здесь очень много черного юмора и насилия, но это и делает фильм таким какой он есть. Хотя он и не стал лидером проката, он собрал множество наград и стал классикой. Но вернемся в прошлое и перенесемся за океан. В 1994 году вышел фильм «Криминальное чтиво» Квентина Тарантино. По слухам, как-то его спросили — «Квентин, вам не кажется, что вы не сняли ничего лучше Криминального чтива?», на что он ответил — «А кто снял?». Нет, не снял, но снимет через четыре года. Молодой и талантливый режиссер Гай Ричи заставит заговорить о себе весь мир. Со своей картиной «Карты, деньги, два ствола» он не только встанет на один уровень со своим голливудским коллегой Квентином Тарантино и его фильмом «Криминальное чтиво», но и превзойдет его. Впрочем, здесь достаточно трудно утверждать чей фильм лучше, а чей хуже: оба этих фильма гениальны, однако свое предпочтение я все же отдам Гаю Ричи. А теперь, после того, как я похвалила режиссера, можно перейти к самой картине. О ней только и можно сказать что она невероятна. Именно такой и видится криминальный мир Лондона. Здесь есть все составляющие для хорошего кино. Все актеры подобраны идеально и стоят на своем месте. Стоит ли говорить, что после этого фильма Джейсон Стэйтем проснулся звездой. Кроме потрясающей режиссерской работы, здесь ещё и отличный сценарий, написанный так же Гаем Ричи. Все диалоги настолько хороши, что во время просмотра хочется взять бумагу и ручку и записать их. Так же к диалогам подобрано отличное музыкальное сопровождение. С первых минут фильм кажется ничем не примечательным, и думаешь почему же все считают его культовым. Но потом происходит что-то нереальное. Этот фильм настолько притягивает к себе, что оторваться просто невозможно, настолько интересно наблюдать, как сюжетные линии переплетаются между собой. После просмотра «Карты, деньги, два ствола», просто сидишь в оцепенении и думаешь «Черт возьми, что это было? И хочу ещё!» Безусловно, Гай Ричи создал культовое кино, которое хочется смотреть и пересматривать.\n"
     ]
    }
   ],
   "source": [
    "text = '«Карты, деньги, два ствола» культовый фильм Гая Ричи. Эта картина покорила сначала Британию, затем Америку, а потом и весь мир. Никому неизвестный режиссер Гай Ричи, у которого за плечами были только коротметражка «Трудное дело», дешевые рекламные ролики и клипы, создал шедевр на все времена. Это именно тот случай, когда и критики, и зрители в восторге. Здесь очень много черного юмора и насилия, но это и делает фильм таким какой он есть. Хотя он и не стал лидером проката, он собрал множество наград и стал классикой. Но вернемся в прошлое и перенесемся за океан. В 1994 году вышел фильм «Криминальное чтиво» Квентина Тарантино. По слухам, как-то его спросили — «Квентин, вам не кажется, что вы не сняли ничего лучше Криминального чтива?», на что он ответил — «А кто снял?». Нет, не снял, но снимет через четыре года. Молодой и талантливый режиссер Гай Ричи заставит заговорить о себе весь мир. Со своей картиной «Карты, деньги, два ствола» он не только встанет на один уровень со своим голливудским коллегой Квентином Тарантино и его фильмом «Криминальное чтиво», но и превзойдет его. Впрочем, здесь достаточно трудно утверждать чей фильм лучше, а чей хуже: оба этих фильма гениальны, однако свое предпочтение я все же отдам Гаю Ричи. А теперь, после того, как я похвалила режиссера, можно перейти к самой картине. О ней только и можно сказать что она невероятна. Именно такой и видится криминальный мир Лондона. Здесь есть все составляющие для хорошего кино. Все актеры подобраны идеально и стоят на своем месте. Стоит ли говорить, что после этого фильма Джейсон Стэйтем проснулся звездой. Кроме потрясающей режиссерской работы, здесь ещё и отличный сценарий, написанный так же Гаем Ричи. Все диалоги настолько хороши, что во время просмотра хочется взять бумагу и ручку и записать их. Так же к диалогам подобрано отличное музыкальное сопровождение. С первых минут фильм кажется ничем не примечательным, и думаешь почему же все считают его культовым. Но потом происходит что-то нереальное. Этот фильм настолько притягивает к себе, что оторваться просто невозможно, настолько интересно наблюдать, как сюжетные линии переплетаются между собой. После просмотра «Карты, деньги, два ствола», просто сидишь в оцепенении и думаешь «Черт возьми, что это было? И хочу ещё!» Безусловно, Гай Ричи создал культовое кино, которое хочется смотреть и пересматривать.'\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "карты деньги два ствола культовый фильм гая ричи эта картина\n"
     ]
    }
   ],
   "source": [
    "prog = re.compile('[А-Яа-я\\-]+')\n",
    "tokens = prog.findall(text.lower())\n",
    "print(' '.join(tokens[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Сегментация предложений__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Первое предложение.\n",
      "Второе предложение!\n",
      "И, наконец, третье?\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "text1 = 'Первое предложение. Второе предложение! И, наконец, третье?'\n",
    "sents = sent_tokenize(text1)\n",
    "\n",
    "print(len(sents))\n",
    "print(*sents, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Частотный анализ текста__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 самых частых слов (токенов):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('и', 22),\n",
       " ('что', 7),\n",
       " ('фильм', 6),\n",
       " ('ричи', 6),\n",
       " ('все', 6),\n",
       " ('не', 6),\n",
       " ('но', 5),\n",
       " ('он', 5),\n",
       " ('а', 4),\n",
       " ('на', 4)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "d1 = nltk.FreqDist(tokens) # частотный словарь для текста\n",
    "d1.most_common(10) # токен и кол-во его появлений в тексте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределение длин слов в тексте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 14 samples and 363 outcomes>\n",
      "[(5, 56), (3, 46), (6, 41), (1, 39), (7, 38)]\n",
      "0.15426997245179064\n"
     ]
    }
   ],
   "source": [
    "d2 = nltk.FreqDist(len(w) for w in tokens)  \n",
    "\n",
    "print(d2)  \n",
    "print(d2.most_common(5)) # 5 самых частых длин слов\n",
    "print(d2.freq(d2.max())) # как часто они встречаются в тексте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задание 2:__\n",
    "\n",
    "1. Посчитайте, сколько слов в тексте про Гая Ричи встречается больше 3 раз.\n",
    "2. Посчитайте количество слов, состоящих из 5 букв и более."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Лемматизация текста__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'Безусловно, Гай Ричи создал культовое кино, которое хочется смотреть и пересматривать.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pymorphy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "безусловно, гай ричать создать культовый кино, который хотеться смотреть и пересматривать.\n",
      "CPU times: user 74 ms, sys: 39.8 ms, total: 114 ms\n",
      "Wall time: 198 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "m = MorphAnalyzer()\n",
    "lemmas1 = [m.parse(word)[0].normal_form for word in sent.split()]\n",
    "print(' '.join(lemmas1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mystem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymystem3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pymystem3'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "m = Mystem()\n",
    "lemmas2 = m.lemmatize(sent)\n",
    "print(''.join(lemmas2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='стали', tag=OpencorporaTag('VERB,perf,intr plur,past,indc'), normal_form='стать', score=0.984662, methods_stack=((<DictionaryAnalyzer>, 'стали', 904, 4),)),\n",
       " Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn sing,gent'), normal_form='сталь', score=0.003067, methods_stack=((<DictionaryAnalyzer>, 'стали', 13, 1),)),\n",
       " Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn sing,datv'), normal_form='сталь', score=0.003067, methods_stack=((<DictionaryAnalyzer>, 'стали', 13, 2),)),\n",
       " Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn sing,loct'), normal_form='сталь', score=0.003067, methods_stack=((<DictionaryAnalyzer>, 'стали', 13, 5),)),\n",
       " Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn plur,nomn'), normal_form='сталь', score=0.003067, methods_stack=((<DictionaryAnalyzer>, 'стали', 13, 6),)),\n",
       " Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn plur,accs'), normal_form='сталь', score=0.003067, methods_stack=((<DictionaryAnalyzer>, 'стали', 13, 9),))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = MorphAnalyzer()\n",
    "\n",
    "m.parse('стали')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUN,anim,masc sing,nomn\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "p = m.parse('кот')[0]\n",
    "print(p.tag)\n",
    "print({'anim', 'nomn'} in p.tag)\n",
    "print({'VERB'} in p.tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обозначения для граммем: http://pymorphy2.readthedocs.io/en/latest/user/grammemes.html#grammeme-docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3\n",
    "\n",
    "Найдите в списке персонажей романа \"Война и мир\" все уникальные  женские имена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('persons.txt') as f:\n",
    "    raw = f.read()\n",
    "    \n",
    "# здесь Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "распределен\n",
      "пристав\n",
      "сдела\n",
      "словообразован\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import RussianStemmer\n",
    "\n",
    "stemmer = RussianStemmer()\n",
    "words = ['распределение', 'приставить', 'сделала', 'словообразование']\n",
    "for w in words:\n",
    "    stem = stemmer.stem(w)\n",
    "    print(stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Удаление стоп-слов__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "«Карты, деньги, два ствола» культовый фильм Гая Ричи. Эта картина покорила сначала Британию, затем Америку, а потом и весь мир. Никому неизвестный режиссер Гай Ричи, у которого за плечами были только коротметражка «Трудное дело», дешевые рекламные ролики и клипы, создал шедевр на все времена. Это именно тот случай, когда и критики, и зрители в восторге. Здесь очень много черного юмора и насилия, но это и делает фильм таким какой он есть. Хотя он и не стал лидером проката, он собрал множество наград и стал классикой. Но вернемся в прошлое и перенесемся за океан. В 1994 году вышел фильм «Криминальное чтиво» Квентина Тарантино. По слухам, как-то его спросили — «Квентин, вам не кажется, что вы не сняли ничего лучше Криминального чтива?», на что он ответил — «А кто снял?». Нет, не снял, но снимет через четыре года. Молодой и талантливый режиссер Гай Ричи заставит заговорить о себе весь мир. Со своей картиной «Карты, деньги, два ствола» он не только встанет на один уровень со своим голливудским коллегой Квентином Тарантино и его фильмом «Криминальное чтиво», но и превзойдет его. Впрочем, здесь достаточно трудно утверждать чей фильм лучше, а чей хуже: оба этих фильма гениальны, однако свое предпочтение я все же отдам Гаю Ричи. А теперь, после того, как я похвалила режиссера, можно перейти к самой картине. О ней только и можно сказать что она невероятна. Именно такой и видится криминальный мир Лондона. Здесь есть все составляющие для хорошего кино. Все актеры подобраны идеально и стоят на своем месте. Стоит ли говорить, что после этого фильма Джейсон Стэйтем проснулся звездой. Кроме потрясающей режиссерской работы, здесь ещё и отличный сценарий, написанный так же Гаем Ричи. Все диалоги настолько хороши, что во время просмотра хочется взять бумагу и ручку и записать их. Так же к диалогам подобрано отличное музыкальное сопровождение. С первых минут фильм кажется ничем не примечательным, и думаешь почему же все считают его культовым. Но потом происходит что-то нереальное. Этот фильм настолько притягивает к себе, что оторваться просто невозможно, настолько интересно наблюдать, как сюжетные линии переплетаются между собой. После просмотра «Карты, деньги, два ствола», просто сидишь в оцепенении и думаешь «Черт возьми, что это было? И хочу ещё!» Безусловно, Гай Ричи создал культовое кино, которое хочется смотреть и пересматривать.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('фильм', 9),\n",
       " ('гай', 6),\n",
       " ('ричать', 6),\n",
       " ('криминальный', 4),\n",
       " ('снять', 4),\n",
       " ('свой', 4),\n",
       " ('карта', 3),\n",
       " ('деньга', 3),\n",
       " ('ствол', 3),\n",
       " ('культовый', 3)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import pymorphy2\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "l = [morph.parse(token)[0].normal_form for token in tokens if not token in stopwords.words('russian')]\n",
    "d3 = nltk.FreqDist(l)\n",
    "d3.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "0.017777777777777778\n"
     ]
    }
   ],
   "source": [
    "print (d3['снять'])\n",
    "print (d3.freq('снять'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Удаление небуквенных символов:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уфологи уверены, что таинственная планета \"Нибиру\" не только существует, но и обнаружена в 2007 году. По их словам, в NASA до сих пор не могут решить, отнести небесное тело под кодовым номером OGLE-2016-BLG-1190Lb к числу планет или звезд.\n"
     ]
    }
   ],
   "source": [
    "s = 'Уфологи уверены, что таинственная планета \"Нибиру\" не только существует, но и обнаружена в 2007 году. По их словам, в NASA до сих пор не могут решить, отнести небесное тело под кодовым номером OGLE-2016-BLG-1190Lb к числу планет или звезд.'\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "уфолог уверить что таинственный планет нибира не только существовать но и обнаружить в год по они слово в до сей пора не мочь решить отнести небесный тело под кодовый номер к число планета или звезда\n"
     ]
    }
   ],
   "source": [
    "prog = re.compile('[А-Яа-я\\-]+')\n",
    "tokens2 = prog.findall(s)\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "l2 = [morph.parse(token)[0].normal_form for token in tokens2 if token.isalpha()]\n",
    "\n",
    "print(*l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __NLTK-текст__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Александр Милн , Борис Заходер Винни-Пух ПРЕДИСЛОВИЕ Ровно...>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Vinni-Puh.txt') as f:\n",
    "    raw = f.read()\n",
    "    \n",
    "tokens = nltk.word_tokenize(raw)\n",
    "nltk_text = nltk.Text(tokens)\n",
    "nltk_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 25 matches:\n",
      "се новые Шумелки , Пыхтелки и Вопилки Пух сочинял под моим руководством . Слово\n",
      "ать , как было раньше ) . Во-вторых , Пух с друзьями разместились в целых двух \n",
      " папа . Вот однажды , гуляя по лесу , Пух вышел на полянку . На полянке рос выс\n",
      "ь на такие вышки ! По правде говоря , Пух уже порядком устал , поэтому Пыхтелка\n",
      "точку — и… ТРРАХ ! — Мама ! — крикнул Пух , пролетев добрых три метра вниз и чу\n",
      " , что я слишком люблю мёд ! Мама ! … Пух выкарабкался из тернового куста , выт\n",
      "рое утро , Кристофер Робин ! — сказал Пух . — Доброе утро , Винни-Пух ! — сказа\n",
      " — Мёд . — Что-о ? — Мёд ! — повторил Пух . — Кто же это ходит за мёдом с возду\n",
      "здушными шарами ? — Я хожу ! — сказал Пух . Ну , а как раз накануне Кристофер Р\n",
      "равится ? — спросил Кристофер Робин . Пух обхватил голову лапами и задумался . \n",
      "у разве не похож ? — тревожно спросил Пух . — Не очень . — Ну ладно , может быт\n",
      "ову ! К сожалению , ветра не было , и Пух повис в воздухе совершенно неподвижно\n",
      "релишь , тогда испорчусь я , — сказал Пух . Конечно , тут Кристофер Робин сразу\n",
      "то , чтобы совсем не попал , — сказал Пух , — но только не попал в шарик ! — Пр\n",
      "то забываю… — Ну , например , однажды Пух и Пятачок решили поймать Слонопотама…\n",
      "али они его ? — Нет . — Где им ! Ведь Пух совсем глупенький . А я его поймал ? \n",
      "маешь , папа , я-то всё помню , а вот Пух забыл , и ему очень-очень интересно п\n",
      "иногда для краткости его звали просто Пух ) не спеша прогуливался по Лесу с дов\n",
      " была большая дыра . — Ага ! — сказал Пух . ( Трам-пам-пам-тарарам-пам-па ! ) —\n",
      "« Эй ! Кто-нибудь дома ? » — повторил Пух громко-громко . — Нет ! — ответил чей\n",
      "жен быть похож ! — Вот как ? — сказал Пух . Он снова вытащил голову наружу , ещ\n",
      "ть — мёду или сгущённого молока ? » — Пух пришёл в такой восторг , что выпалил \n",
      "ос у него стал прямо-таки медовый ! — Пух встал из-за стола , от всей души пожа\n",
      "то-нибудь есть ? — с надеждой спросил Пух , снова оживляясь . Кролик заглянул в\n",
      "Я так и думал , — сочувственно сказал Пух , покачав головой . — Ну , до свидань\n"
     ]
    }
   ],
   "source": [
    "nltk_text.concordance(\"Пух\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "и спросил он вот если закричал тогда а ведь только так что но видел\n",
      "был подумал крикнул повторил знаю пискнул\n"
     ]
    }
   ],
   "source": [
    "nltk_text.similar('сказал') #контекстуальные синонимы для слова \"сказал\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "а_думал нет_не пух_не разве_не что_говорил что_должен\n"
     ]
    }
   ],
   "source": [
    "nltk_text.common_contexts([\"ты\", \"я\"]) #общие контексты для слов \"ты\" и \"я\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кристофер Робин; сказал Пух; Кристофера Робина; потому что; может\n",
      "быть; Кристоферу Робину; сказала Кенга; сказала Сова; сказал Кролик;\n",
      "сказал Кристофер\n"
     ]
    }
   ],
   "source": [
    "nltk_text.collocations(10) #коллокации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задание 4:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Лемматизируйте текст про Винни Пуха.\n",
    "2. Найдите 10 самых частотных лемм.\n",
    "3. Удалите все стоп-слова и небуквенные символы. Найдите 10 самых частотных лемм (без стоп-слов).\n",
    "4. Проверьте закон Ципфа на примере данного текста: постройте на одном графике график функции 1/n и кривую Ципфа. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В папке лежит коллекция текстов 'recipes.txt' (кулинарные рецепты), разбитая по темам: супы, салаты и десерты. Проведем предобработку каждого текста, выделим ключевые слова для каждой категории с помощью tf-idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('soups.txt') as data_file:    \n",
    "    soups_raw = data_file.read()\n",
    "    \n",
    "with open('salads.txt') as data_file:    \n",
    "    salads_raw = data_file.read()\n",
    "    \n",
    "with open('desserts.txt') as data_file:    \n",
    "    desserts_raw = data_file.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "recipes = [] #массив со всеми рецептами\n",
    "\n",
    "#soups\n",
    "data = soups_raw.replace(\" г \", \" грамм \").replace(\" л \", \" литр \").replace(\" ст. \", \" столовая \")\n",
    "tokens = word_tokenize(data)\n",
    "d = [morph.parse(token)[0].normal_form for token in tokens if not token.lower() in stopwords.words('russian')]\n",
    "words = [ch.lower() for ch in d if ch.isalpha()] \n",
    "soups = ' '.join([w for w in words])\n",
    "recipes.append(soups)\n",
    "\n",
    "#salads\n",
    "data = salads_raw.replace(\" г \", \" грамм \").replace(\" л \", \" литр \").replace(\" ст. \", \" столовая \")\n",
    "tokens = word_tokenize(data)\n",
    "d = [morph.parse(token)[0].normal_form for token in tokens if not token.lower() in stopwords.words('russian')]\n",
    "words = [ch.lower() for ch in d if ch.isalpha()] \n",
    "salads = ' '.join([w for w in words])\n",
    "recipes.append(salads)\n",
    "\n",
    "#desserts\n",
    "data = desserts_raw.replace(\" г \", \" грамм \").replace(\" л \", \" литр \").replace(\" ст. \", \" столовая \") \n",
    "tokens = word_tokenize(data)\n",
    "d = [morph.parse(token)[0].normal_form for token in tokens if not token.lower() in stopwords.words('russian')]\n",
    "words = [ch.lower() for ch in d if ch.isalpha()] \n",
    "desserts = ' '.join([w for w in words])\n",
    "recipes.append(desserts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1,1), min_df = 0)\n",
    "tfidf_matrix =  tfidf.fit_transform(recipes)\n",
    "feature_names = tfidf.get_feature_names() \n",
    "\n",
    "categories = ['soups', 'salads', 'desserts']\n",
    "\n",
    "df = []\n",
    "dense = tfidf_matrix.todense()\n",
    "for i in range(3):\n",
    "    text = dense[i].tolist()[0]\n",
    "    phrase_scores = [pair for pair in zip(range(0, len(text)), text) if pair[1] > 0]\n",
    "    sorted_phrase_scores = sorted(phrase_scores, key=lambda t: t[1] * -1)\n",
    "    phrases = []\n",
    "    for phrase, score in [(feature_names[word_id], score) for (word_id, score) in sorted_phrase_scores][:50]:\n",
    "        phrases.append(phrase)\n",
    "    df.append([ categories[i], ' '.join(phrases)])\n",
    "result = pd.DataFrame.from_records(df, columns = ['category','terms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soups</td>\n",
       "      <td>грамм бульон суп вода варить нарезать минута л...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>salads</td>\n",
       "      <td>грамм салат нарезать ложка соль столовый огуре...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>desserts</td>\n",
       "      <td>грамм масло стакан тесто ложка яйцо мука вода ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                              terms\n",
       "0     soups  грамм бульон суп вода варить нарезать минута л...\n",
       "1    salads  грамм салат нарезать ложка соль столовый огуре...\n",
       "2  desserts  грамм масло стакан тесто ложка яйцо мука вода ..."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "Полные тексты сообщений\n",
      "Fresher (fresher.ru), Москва, 21 января 2017\n",
      "ИНАУГУРАЦИЯ 45-ГО ПРЕЗИДЕНТА США ДОНАЛЬДА ТРАМПА\n",
      "В полдень 20 января (20:00 мск) миллиардер Трамп стал хозяином Белого дома, сменив на этом посту Барака Обаму \n",
      "Ранним утром 20 января 2017 года здание Капитолия в Вашингтоне было готово к инаугурации нового президента США. Традиция проводить церемонию в западном крыле Капитолия ведется с 20 января 1981 года, когда на пост президента США заступил Рональд Рейган. \n",
      "Мормонский табернакальный хор, существующий с 1973 года, не впервые принял участие в церемонии инаугурации президента США. Хор пел во время вступления в должность главы Белого дома Линдона Джонсона в 1965 году, Ричарда Никсона - в 1969-м, Рональда Рейгана - в 1981-м и Джорджа Буша-старшего (в 1989 году) и Джорджа Буша-младшего (в 2001-м). \n",
      "Действующий президент США Барак Обама и его жена Мишель у входа в Белый дом ожидают избранного президента Дональда Трампа с супругой Меланией на традиционное чаепитие. Через полтора часа Обама передаст Трампу полномочия главы государства, которое он возглавлял в течении восьми лет. По давней традиции Обама оставил записку новому президенту - Дональду Трампу, положив ее в верхний ящик рабочего стола в Овальном кабинете. \n",
      "На чаепитие с четой Обамы супруга избранного президента США Мелания Трамп прибыла с подарком для Мишель Обамы - элегантным пакетом цвета тиффани. \n",
      "На церемонии вступления республиканца Дональда Трампа в должность 45-го президента США присутствовал 39-й президент, демократ Джимми Картер с супругой Розалин. Картер занимал Овальный кабинет Белого дома с 1977 по 1981 год. Сменивший его 40-й президент США Рональд Рейган и следующий за ним 41-й президент Джордж Буш-старший на инаугурации Трампа не присутствовали. Рейган скончался в 2004 году. А Буш-старший был госпитализирован за несколько дней до инаугурации Трампа. \n",
      "На церемонию инаугурации Трампа прибыл 43-й президент США Джордж Буш-младший (2001-2009 годы) с супругой Лорой \n",
      "Среди почетных гостей церемонии инаугурации были бывший президент США Билл Клинтон (1993-2001 годы) и его супруга Хиллари Клинтон. Она была соперницей Трампа на президентских выборах и до последнего дня большинство опросов отдавали ей лидерство в президентской гонке. \n",
      "Избранный президент США Дональд Трамп появился перед собравшимися в западном крыле Капитолия, чтобы принести присягу и вступить в должность 45-го президента США \n",
      "Десятки тысяч человек собрались перед Капитолием в Вашингтоне, чтобы собственными глазами увидеть вступление Дональда Трампа в должность президента США и услышать его слова \"Америка - прежде всего!\" \n",
      "В центре Вашингтона около полутора сотен человек проводили акцию протеста против Трампа. Они били стекла автомобилей и витрины магазинов. Пострадал в том числе офис Bank of America и кофейня Starbucks. \n",
      "Полиция применила против демонстрантов, выступающих против Трампа, слезоточивый газ. \n",
      "Протесты против нового президента США прошли также в ряде других стран. В том числе - у посольства США в Лондоне. \n",
      "Барак Обама поздравляет Дональда Трампа на церемонии инаугурации нового президента США. \n",
      "Новый президент США Дональд Трамп и члены его семьи на церемонии инаугурации у стен Капитолия в Вашингтоне. \n",
      "После выступления и поздравлений, Дональд Трамп и Мелани проводили Барака Обаму и Мишель к вертолету на лужайке у здания Капитолия. Из Вашингтона Барак и Мишель Обама вылетели на авиабазу Joint Base Andrews, расположенную в 25 км от Вашингтона. Оттуда, попрощавшись с работниками авиабазы, где базируется президентский борт \"номер один\", они отправились на отдых в Палм-Спрингс в Калифорнии. \n",
      "Бараку Обаме 55 лет. На посту президента США он находился с 20 января 2009 года по 20 января 2017 года. \n",
      "Инаугурация 45-го президента США Дональда Трампа\n",
      "Инаугурация 45-го президента США Дональда Трампа\n",
      "Инаугурация 45-го президента США Дональда Трампа\n",
      "Инаугурация 45-го президента США Дональда Трампа\n",
      "Инаугурация 45-го президента США Дональда Трампа\n",
      "Инаугурация 45-го президента США Дональда Трампа\n",
      "Инаугурация 45-го президента США Дональда Трампа\n",
      "Инаугурация 45-го президента США Дональда Трампа\n",
      "Инаугурация 45-го президента США Дональда Трампа\n",
      "Инаугурация 45-го президента США Дональда Трампа\n",
      "Инаугурация 45-го президента США Дональда Трампа\n",
      "Инаугурация 45-го президента США Дональда Трампа\n",
      "Инаугурация 45-го президента США Дональда Трампа\n",
      "Инаугурация 45-го президента США Дональда Трампа\n",
      "Инаугурация 45-го президента США Дональда Трампа\n",
      "Инаугурация 45-го президента США Дональда Трампа\n",
      "http://www.fresher.ru/2017/01/21/inauguraciya-45-go-prezidenta-ssha-donalda-trampa/\n"
     ]
    }
   ],
   "source": [
    "with open('trump.txt') as f: # в файле лежит 51 новостоной текст про избрание Трампа президентом, разделенных '\\n\\n'\n",
    "    text = f.read()          \n",
    "\n",
    "    \n",
    "    \n",
    "doc_set = text.split('\\n\\n')\n",
    "print(len(doc_set))\n",
    "print(doc_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['полные', 'тексты', 'сообщений', 'fresher', 'fresher', 'ru', 'москва', '21', 'января', '2017']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "raw = [doc.lower() for doc in doc_set]\n",
    "no_urls = [re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', t) for t in raw]\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens = [tokenizer.tokenize(r) for r in no_urls]\n",
    "print(tokens[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['полные', 'тексты', 'сообщений', 'fresher', 'fresher', 'ru', 'москва', 'января', 'инаугурация', 'го']\n"
     ]
    }
   ],
   "source": [
    "stopped_tokens = [[w for w in t if w.isalpha() and not w in stopwords.words('russian')] for t in tokens]\n",
    "\n",
    "print(stopped_tokens[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "lemmas = [[morph.parse(t)[0].normal_form for t in tokens] for tokens in stopped_tokens] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 943 ms, sys: 224 ms, total: 1.17 s\n",
      "Wall time: 1.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(lemmas, size=100, window=5, min_count=5, workers=4)\n",
    "model.save(\"izv_w2v.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Синонимы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('сша', 0.999905526638031),\n",
       " ('президент', 0.9998775124549866),\n",
       " ('январь', 0.9998767971992493),\n",
       " ('инаугурация', 0.9998635053634644),\n",
       " ('избранный', 0.999793291091919),\n",
       " ('состояться', 0.9997864961624146),\n",
       " ('москва', 0.9997209906578064),\n",
       " ('церемония', 0.9996782541275024),\n",
       " ('дональд', 0.999654233455658),\n",
       " ('должность', 0.9996520280838013),\n",
       " ('кабинет', 0.9996214509010315),\n",
       " ('время', 0.9996209144592285),\n",
       " ('присяга', 0.9995948076248169),\n",
       " ('вашингтон', 0.9995070695877075),\n",
       " ('республиканец', 0.9994803071022034)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"трамп\", topn=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ассоциации вида (мужчина : король = женщина : королева)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('глава', 0.9995779991149902),\n",
       " ('россия', 0.9995577335357666),\n",
       " ('стать', 0.9995557069778442),\n",
       " ('демократ', 0.9995537996292114),\n",
       " ('свой', 0.9995518922805786),\n",
       " ('новый', 0.9995412230491638),\n",
       " ('вашингтон', 0.9995331168174744),\n",
       " ('новое', 0.9995326399803162),\n",
       " ('который', 0.9995190501213074),\n",
       " ('день', 0.9995185136795044)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=[\"путин\",\"сша\"], negative=[\"трамп\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лишнее слово:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'путин'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"обама трамп путин сша вашингтон\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительно: Синтаксический анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clickhouse какая СУБД .\n",
      "\n",
      "столбцовая СУБД . \n",
      "\n",
      "что такое INNER JOIN .\n",
      "\n",
      "Почему Очень важно хранить данные компактно .\n",
      "\n",
      "Что защищает от аппаратных сбоев .\n",
      "\n",
      "Что могут иметь функции и операторы в качестве аргументов .\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('sentences.txt') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск SyntaxNet из Docker: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?.\r\n",
      "See 'docker run --help'.\r\n"
     ]
    }
   ],
   "source": [
    "! cat sentences.txt | docker run --rm -i inemo/syntaxnet_rus > data.conll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представление результатов с помощью Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import DependencyGraph\n",
    "import codecs\n",
    "\n",
    "processed_sentences = []\n",
    "sentence = []\n",
    "for line in codecs.open('data.conll', 'r', 'utf-8'):\n",
    "    if len(line) == 1:\n",
    "        processed_sentences.append(sentence)\n",
    "        sentence = []\n",
    "    else:\n",
    "        word = line.split(\"\\t\")\n",
    "        sentence.append(word)\n",
    "\n",
    "deps = []\n",
    "for sentence in processed_sentences:\n",
    "    s = u\"\"\n",
    "    for line in sentence:\n",
    "        s += u\"\\t\".join(line) + u'\\n'\n",
    "    deps.append(s)\n",
    "\n",
    "for sent_dep in deps:\n",
    "    graph = DependencyGraph(tree_str=sent_dep)\n",
    "    for triple in graph.triples():\n",
    "        for e in triple:\n",
    "            print(e[0] if isinstance(e, tuple) else e,)\n",
    "        print()\n",
    "    print()\n",
    "    tree = graph.tree()\n",
    "    print(tree.pretty_print())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent_dep in deps:\n",
    "    verbs = {}\n",
    "    for t in sent_dep.split('\\n'):\n",
    "        if len(t) > 1:\n",
    "            splt = t.split('\\t')\n",
    "            if splt[3] == 'VERB':\n",
    "                verbs[splt[0]] = [splt[1]]\n",
    "    sent_split = sent_dep.split('\\n')\n",
    "    sent = [i.split('\\t') for i in sent_split if len(i) > 1]\n",
    "    for splt in sent:\n",
    "        if splt[7] in ['dobj', 'nsubj']:\n",
    "            if splt[6] in verbs:\n",
    "                verbs[splt[6]].append(splt[1])\n",
    "                \n",
    "                \n",
    "    for t in verbs.values():\n",
    "        for elem in t:\n",
    "            print(elem)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5.\n",
    "\n",
    "1. Исправьте данный код, чтобы он учитывал однородные члены при разборе предложения.\n",
    "2. Найдите в тексте про Винни Пуха все SVO-тройки, где субъектом выступает Сова."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
